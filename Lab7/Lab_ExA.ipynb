{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis - Lab 7\n",
    "### M. SÃ©bastien MASCHA & M. Pierre SAUVAGE\n",
    "### ISEP Paris   |   2019-2020\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "___\n",
    "\n",
    "# Exercice A - Text processing with NLTK\n",
    "*The Natural Language Toolkit, or NLTK for short, is a Python library written for\n",
    "working and modeling text. It provides good tools for loading and cleaning text\n",
    "that we can use to get our data ready for working with machine learning and deep\n",
    "learning algorithms.*\n",
    "\n",
    "### Import of libraries\n",
    "\n",
    "This document has been done using python on Jupyter Notebook with the librairies:\n",
    "\n",
    "- maths for sqrt, pi, exp\n",
    "- Numpy to manipulate arrays\n",
    "- pandas to import csv\n",
    "- matplotlib to plot graphics\n",
    "- seaborn to make your charts prettier (built on top of Matplotlib)\n",
    "- sklearn : tools for data mining and data analysis\n",
    "- SciPy : a Python-based ecosystem of open-source software for mathematics, science, and engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import data\n",
    "\n",
    "from math import sqrt,pi,exp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sklearn\n",
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "# Useful \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import scipy\n",
    "\n",
    "import nltk \n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "___\n",
    "### Question 1 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39c00d2295ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetamorphosis_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'metamorphosis_clean.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetamorphosis_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "# Code\n",
    "metamorphosis_clean = 'metamorphosis_clean.txt'\n",
    "file(metamorphosis_clean, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
